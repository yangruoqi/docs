{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "071b8adc",
   "metadata": {},
   "source": [
    "# Callback回调机制\n",
    "\n",
    "[![下载Notebook](https://gitee.com/mindspore/docs/raw/tutorials-develop/resource/_static/logo_notebook.png)](https://obs.dualstack.cn-north-4.myhuaweicloud.com/mindspore-website/notebook/tutorials-develop/tutorials/zh_cn/mindspore_callback.ipynb)&emsp;\n",
    "[![下载样例代码](https://gitee.com/mindspore/docs/raw/tutorials-develop/resource/_static/logo_download_code.png)](https://obs.dualstack.cn-north-4.myhuaweicloud.com/mindspore-website/notebook/tutorials-develop/tutorials/zh_cn/mindspore_callback.py)&emsp;\n",
    "[![查看源文件](https://gitee.com/mindspore/docs/raw/tutorials-develop/resource/_static/logo_source.png)](https://gitee.com/mindspore/docs/blob/tutorials-develop/tutorials/source_zh_cn/intermediate/callback.ipynb)\n",
    "\n",
    "在深度学习训练过程中，为及时掌握网络模型的训练状态、实时观察网络模型各参数的变化情况和实现训练过程中用户自定义的一些操作，MindSpore提供了Callback回调机制。\n",
    "\n",
    "Callback回调机制一般用在网络模型训练过程`Model.train`中，MindSpore会按照Callback列表`callbacks`顺序执行回调函数，用户可以通过配置不同的回调函数来实现不同功能。\n",
    "\n",
    "## 常用的内置回调函数\n",
    "\n",
    "下面以基于MNIST数据集训练LeNet-5网络模型为例，介绍几种常用的MindSpore内置回调函数。\n",
    "\n",
    "> 更多内置回调函数信息及使用方式请参考[API文档](https://www.mindspore.cn/docs/api/zh-CN/master/api_python/mindspore.train.html#mindspore-train-callback)。\n",
    "\n",
    "- ModelCheckpoint，保存训练后的模型和网络参数，方便进行再推理或再训练。\n",
    "- LossMonitor，监控训练过程中的损失函数值Loss变化情况。\n",
    "- TimeMonitor，监控训练过程中每个epoch、每个step的运行时间。\n",
    "\n",
    "!!!zhaoyu，LossMonitor和TimeMonitor在套件中用统一接口展示，另外套件针对推理还提供了接口，请展示。\n",
    "\n",
    "!!!zhaoyu,callback建议都拆出来成一个目录，里面有三个内容，1个ModelCheckpoint，一个套件的Monitor，一个也是套件里面有的接口：https://mindspore.cn/docs/programming_guide/zh-CN/master/evaluate_the_model_during_training.html。\n",
    "\n",
    "使用示例："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ceff845d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1 step: 300, loss is 2.295940399169922\n",
      "epoch: 1 step: 600, loss is 2.301466226577759\n",
      "epoch: 1 step: 900, loss is 0.3619288206100464\n",
      "epoch: 1 step: 1200, loss is 0.06575474143028259\n",
      "epoch: 1 step: 1500, loss is 0.16204708814620972\n",
      "epoch: 1 step: 1800, loss is 0.004415267147123814\n",
      "epoch time: 16472.533 ms, per step time: 8.785 ms\n"
     ]
    }
   ],
   "source": [
    "import mindspore.nn as nn\n",
    "from mindspore.train import Model\n",
    "from mindspore.train.callback import ModelCheckpoint, CheckpointConfig, TimeMonitor, LossMonitor\n",
    "\n",
    "from mindvision.classification.dataset import Mnist\n",
    "from mindvision.classification.models import lenet\n",
    "\n",
    "download_train = Mnist(path=\"./mnist\", split=\"train\", batch_size=32, repeat_num=1, shuffle=True, resize=32, download=True)\n",
    "dataset_train = download_train.run()\n",
    "\n",
    "network = lenet(num_classes=10, pretrained=False)\n",
    "net_loss = nn.SoftmaxCrossEntropyWithLogits(sparse=True, reduction='mean')\n",
    "net_opt = nn.Momentum(network.trainable_params(), learning_rate=0.01, momentum=0.9)\n",
    "model = Model(network, loss_fn=net_loss, optimizer=net_opt, metrics={'acc'})\n",
    "\n",
    "config_ck = CheckpointConfig(save_checkpoint_steps=1875, keep_checkpoint_max=10)\n",
    "ckpoint = ModelCheckpoint(prefix=\"lenet\", directory=\"./lenet\", config=config_ck)\n",
    "\n",
    "# !!!代码加上简单注释，特别是针对Monitor\n",
    "model.train(1, dataset_train, callbacks=[ckpoint, LossMonitor(300), TimeMonitor(1)], dataset_sink_mode=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4da7d0e2",
   "metadata": {},
   "source": [
    "!!!zhaoyu，套件针对推理还提供了接口，请展示"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76444d7e",
   "metadata": {},
   "source": [
    "生成的Checkpoint文件目录结构如下：\n",
    "\n",
    "```text\n",
    "./lenet/\n",
    "├── lenet-1_1875.ckpt # 保存参数文件\n",
    "└── lenet-graph.meta # 编译后的计算图\n",
    "```\n",
    "\n",
    "## 自定义回调函数\n",
    "\n",
    "MindSpore不仅有功能强大的内置回调函数，当用户有自己的特殊需求时，还可以基于`Callback`基类自定义回调函数。\n",
    "\n",
    "回调机制可以把训练过程中的重要信息记录下来，通过把一个字典类型变量`RunContext.original_args()`传递给Callback对象，使得用户可以在各个自定义的Callback中获取到相关属性，执行自定义操作，也可以自定义其他变量传递给`RunContext.original_args()`对象。\n",
    "\n",
    "`RunContext.original_args()`中的常用属性有：\n",
    "\n",
    "- loss_fn：损失函数\n",
    "- optimizer：优化器\n",
    "- train_dataset：训练的数据集\n",
    "- epoch_num：训练的epoch的数量\n",
    "- batch_num：一个epoch中step的数量\n",
    "- train_network：训练的网络\n",
    "- cur_epoch_num：当前的epoch数\n",
    "- cur_step_num：当前的step数\n",
    "- parallel_mode：并行模式\n",
    "- list_callback：所有的Callback函数\n",
    "- net_outputs：网络的输出结果\n",
    "\n",
    "通过下面两个场景，我们可以增加对自定义Callback回调函数功能的了解。\n",
    "\n",
    "1. 实现在规定时间内终止训练。用户可以设定时间阈值，当训练时间达到这个阈值后就终止训练过程。\n",
    "\n",
    "!!!zhaoyu，代码实现方式参考套件中的接口，这里的输出没有格式化，另外需要加上代码的解释，这里面用了很多变量。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fe844740",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "begin training, time is: 1646122014.3542275\n",
      "epoch: 1 step: 200, loss is 0.10437318682670593\n",
      "epoch: 1 step: 400, loss is 0.08411901444196701\n",
      "epoch: 1 step: 600, loss is 0.16160571575164795\n",
      "epoch: 1 step: 800, loss is 0.008495703339576721\n",
      "epoch: 1 step: 1000, loss is 0.013355637900531292\n",
      "epoch:  1  step:  1172  loss:  0.007238159\n",
      "end training, time is: 1646122024.3574462\n"
     ]
    }
   ],
   "source": [
    "# zhaoyu，注意代码的引用顺序\n",
    "import time\n",
    "\n",
    "from mindspore.train.callback import Callback, LossMonitor\n",
    "\n",
    "class StopAtTime(Callback):\n",
    "    def __init__(self, run_time):\n",
    "        super(StopAtTime, self).__init__()\n",
    "        self.run_time = run_time\n",
    "\n",
    "    def begin(self, run_context):\n",
    "        cb_params = run_context.original_args()\n",
    "        cb_params.init_time = time.time()\n",
    "\n",
    "        print(\"begin training, time is:\", cb_params.init_time)\n",
    "\n",
    "    def step_end(self, run_context):\n",
    "        cb_params = run_context.original_args()\n",
    "        epoch_num = cb_params.cur_epoch_num\n",
    "        step_num = cb_params.cur_step_num\n",
    "        loss = cb_params.net_outputs\n",
    "        cur_time = time.time()\n",
    "\n",
    "        if (cur_time - cb_params.init_time) > self.run_time:\n",
    "            print(\"epoch: \", epoch_num, \" step: \", step_num, \" loss: \", loss)\n",
    "            print(\"end training, time is:\", cur_time)\n",
    "            run_context.request_stop()\n",
    "\n",
    "model.train(1, dataset_train, callbacks=[LossMonitor(200), StopAtTime(10)], dataset_sink_mode=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f0b85d5",
   "metadata": {},
   "source": [
    "2. 实现当loss小于设定的阈值时，保存ckpt文件。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d8ead861",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Save the checkpoint, the loss is:  0.0004997954 the current step num is:  191\n",
      "Save the checkpoint, the loss is:  0.00022582882 the current step num is:  268\n",
      "Save the checkpoint, the loss is:  0.000142571 the current step num is:  269\n",
      "Save the checkpoint, the loss is:  0.00024890315 the current step num is:  381\n",
      "Save the checkpoint, the loss is:  0.0003373801 the current step num is:  932\n",
      "Save the checkpoint, the loss is:  0.00048165582 the current step num is:  1108\n",
      "Save the checkpoint, the loss is:  0.00036466357 the current step num is:  1237\n",
      "Save the checkpoint, the loss is:  0.00012776905 the current step num is:  1687\n",
      "Save the checkpoint, the loss is:  0.00040109223 the current step num is:  1690\n"
     ]
    }
   ],
   "source": [
    "from mindspore import save_checkpoint\n",
    "from mindspore.train.callback import Callback\n",
    "\n",
    "# zhaoyu,请注意代码格式和注释，output我已改过来，参考套件的monitor补充对齐格式。\n",
    "class SaveCallback(Callback):\n",
    "\n",
    "    def step_end(self, run_context):\n",
    "        cb_params = run_context.original_args()\n",
    "        loss = cb_params.net_outputs.asnumpy()\n",
    "\n",
    "        if loss < 5e-4:\n",
    "            file_name = str(cb_params.cur_epoch_num) + \"_\" + str(cb_params.cur_step_num) + \".ckpt\"\n",
    "            save_checkpoint(save_obj=cb_params.train_network, ckpt_file_name=file_name)\n",
    "\n",
    "            print(f\"Saved checkpoint, loss: {loss}, current step num: {cb_params.cur_step_num}.\")\n",
    "\n",
    "model.train(1, dataset_train, callbacks=[SaveCallback()], dataset_sink_mode=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ddb447c",
   "metadata": {},
   "source": [
    "保存目录结构如下：\n",
    "\n",
    "```text\n",
    "./\n",
    "├── 1_191.ckpt\n",
    "├── 1_268.ckpt\n",
    "├── 1_269.ckpt\n",
    "├── 1_381.ckpt\n",
    "├── 1_932.ckpt\n",
    "├── 1_1108.ckpt\n",
    "├── 1_1237.ckpt\n",
    "├── 1_1687.ckpt\n",
    "├── 1_1690.ckpt\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MindSpore",
   "language": "python",
   "name": "mindspore"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
