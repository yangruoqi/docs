{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "071b8adc",
   "metadata": {},
   "source": [
    "# Callback回调机制\n",
    "\n",
    "[![下载Notebook](https://gitee.com/mindspore/docs/raw/tutorials-develop/resource/_static/logo_notebook.png)](https://obs.dualstack.cn-north-4.myhuaweicloud.com/mindspore-website/notebook/tutorials-develop/tutorials/zh_cn/mindspore_callback.ipynb)&emsp;\n",
    "[![下载样例代码](https://gitee.com/mindspore/docs/raw/tutorials-develop/resource/_static/logo_download_code.png)](https://obs.dualstack.cn-north-4.myhuaweicloud.com/mindspore-website/notebook/tutorials-develop/tutorials/zh_cn/mindspore_callback.py)&emsp;\n",
    "[![查看源文件](https://gitee.com/mindspore/docs/raw/tutorials-develop/resource/_static/logo_source.png)](https://gitee.com/mindspore/docs/blob/tutorials-develop/tutorials/source_zh_cn/intermediate/callback.ipynb)\n",
    "\n",
    "在深度学习训练过程中，为及时掌握网络模型的训练状态、实时观察网络模型各参数的变化情况和实现训练过程中用户自定义的一些操作，MindSpore提供了Callback回调机制。\n",
    "\n",
    "Callback回调机制一般用在网络模型训练过程`Model.train`中，MindSpore会按照Callback列表`callbacks`顺序执行回调函数，用户可以通过配置不同的回调函数来实现不同功能。\n",
    "\n",
    "## 常用的内置回调函数\n",
    "\n",
    "下面以基于MNIST数据集训练LeNet-5网络模型为例，介绍几种常用的MindSpore内置回调函数，更多内置回调函数信息及使用方式请参考[API文档](https://www.mindspore.cn/docs/api/zh-CN/master/api_python/mindspore.train.html#mindspore-train-callback)。首先需要下载并处理MNIST数据，构建LeNet-5网络模型，示例代码如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a3657273",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mindspore.nn as nn\n",
    "from mindspore.train import Model\n",
    "from mindvision.classification.dataset import Mnist\n",
    "from mindvision.classification.models import lenet\n",
    "\n",
    "# 使用MindSpore Vision套件提供的Mnist接口下载并处理MNIST数据集\n",
    "download_train = Mnist(path=\"./mnist\", split=\"train\", batch_size=32, repeat_num=1, shuffle=True, resize=32, download=True)\n",
    "download_eval = Mnist(path=\"./mnist\", split=\"test\", batch_size=32, resize=32, download=True)\n",
    "dataset_train = download_train.run()\n",
    "dataset_eval = download_eval.run()\n",
    "\n",
    "# 使用MindSpore Vision套件提供的lenet接口实例化LeNet-5网络模型\n",
    "network = lenet(num_classes=10, pretrained=False)\n",
    "\n",
    "# 定义损失函数\n",
    "net_loss = nn.SoftmaxCrossEntropyWithLogits(sparse=True, reduction='mean')\n",
    "\n",
    "# 定义优化器\n",
    "net_opt = nn.Momentum(network.trainable_params(), learning_rate=0.01, momentum=0.9)\n",
    "\n",
    "# 定义网络模型\n",
    "model = Model(network, loss_fn=net_loss, optimizer=net_opt, metrics={\"Accuracy\": nn.Accuracy()})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78457a88",
   "metadata": {},
   "source": [
    "## ModelCheckpoint\n",
    "\n",
    "为了保存训练后的网络模型和参数，方便进行再推理或再训练，MindSpore提供了[ModelCheckpoint](https://mindspore.cn/docs/api/zh-CN/master/api_python/mindspore.train.html?highlight=modelcheckpoint#mindspore.train.callback.ModelCheckpoint)接口，一般与配置保存信息接口[CheckpointConfig](https://mindspore.cn/docs/api/zh-CN/master/api_python/mindspore.train.html?highlight=modelcheckpoint#mindspore.train.callback.CheckpointConfig)配合使用，下面我们通过一段示例代码来说明如何保存训练后的网络模型和参数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c2150611",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mindspore.train.callback import ModelCheckpoint, CheckpointConfig\n",
    "\n",
    "# 设置保存模型的配置信息\n",
    "config_ck = CheckpointConfig(save_checkpoint_steps=1875, keep_checkpoint_max=10)\n",
    "# 实例化保存模型回调接口，定义保存路径和前缀名\n",
    "ckpoint = ModelCheckpoint(prefix=\"lenet\", directory=\"./lenet\", config=config_ck)\n",
    "\n",
    "# 开始训练，加载保存模型和参数回调函数\n",
    "model.train(1, dataset_train, callbacks=[ckpoint], dataset_sink_mode=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73eb3e57",
   "metadata": {},
   "source": [
    "上面代码运行后，生成的Checkpoint文件目录结构如下：\n",
    "\n",
    "```text\n",
    "./lenet/\n",
    "├── lenet-1_1875.ckpt # 保存参数文件\n",
    "└── lenet-graph.meta # 编译后的计算图\n",
    "```\n",
    "\n",
    "## LossMonitor\n",
    "\n",
    "为了监控训练过程中的损失函数值Loss变化情况，观察训练过程中每个epoch、每个step的运行时间，MindSpore Vision提供了`LossMonitor`接口，下面我们通过示例代码说明："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b7eca826",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:[  0/  1],                     step:[  200/ 1875],                    loss:[0.013/0.045],                    time:6.496,                     lr:0.01000.\n",
      "Epoch:[  0/  1],                     step:[  400/ 1875],                    loss:[0.010/0.052],                    time:6.119,                     lr:0.01000.\n",
      "Epoch:[  0/  1],                     step:[  600/ 1875],                    loss:[0.188/0.050],                    time:5.910,                     lr:0.01000.\n",
      "Epoch:[  0/  1],                     step:[  800/ 1875],                    loss:[0.027/0.052],                    time:7.077,                     lr:0.01000.\n",
      "Epoch:[  0/  1],                     step:[ 1000/ 1875],                    loss:[0.188/0.050],                    time:5.287,                     lr:0.01000.\n",
      "Epoch:[  0/  1],                     step:[ 1200/ 1875],                    loss:[0.014/0.049],                    time:6.299,                     lr:0.01000.\n",
      "Epoch:[  0/  1],                     step:[ 1400/ 1875],                    loss:[0.005/0.049],                    time:6.730,                     lr:0.01000.\n",
      "Epoch:[  0/  1],                     step:[ 1600/ 1875],                    loss:[0.008/0.048],                    time:6.519,                     lr:0.01000.\n",
      "Epoch:[  0/  1],                     step:[ 1800/ 1875],                    loss:[0.009/0.048],                    time:5.381,                     lr:0.01000.\n",
      "Epoch time: 12951.112,                 per step time: 6.907,                 avg loss: 0.047\n"
     ]
    }
   ],
   "source": [
    "from mindvision.engine.callback import LossMonitor\n",
    "\n",
    "# 开始训练，加载保存模型和参数回调函数，LossMonitor的入参0.01为学习率，200为步长\n",
    "model.train(1, dataset_train, callbacks=[LossMonitor(0.01, 200)], dataset_sink_mode=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5878699d",
   "metadata": {},
   "source": [
    "从上面的打印结果可以看出，由于步长设置的是200，所以每200个step会打印一条，loss值会波动，但总体来说loss值会逐步减小，精度逐步提高。每个人运行的loss值有一定随机性，不一定完全相同。\n",
    "\n",
    "## ValAccMonitor\n",
    "\n",
    "为了在训练过程中保存精度最优的网络模型和参数，需要边训练边验证，MindSpore Vision提供了`ValAccMonitor`接口，下面我们通过一段示例来介绍："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb55c62d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mindvision.engine.callback import ValAccMonitor\n",
    "\n",
    "# 开始训练，加载保存模型和参数回调函数\n",
    "model.train(1, dataset_train, callbacks=[ValAccMonitor(model, dataset_eval, num_epochs=1, dataset_sink_mode=False)], dataset_sink_mode=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "942d7a61",
   "metadata": {},
   "source": [
    "上面代码执行后，精度最优的网络模型和参数会被保存在当前目录下，文件名为\"best.ckpt\"，打印结果如下：\n",
    "\n",
    "```text\n",
    "--------------------\n",
    "Epoch: [  1 /   1],                   Train Loss: [0.135],                   Accuracy:  0.988.\n",
    "================================================================================\n",
    "End of validation the best Accuracy is:  0.988,               save the best ckpt file in ./best.ckpt\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76444d7e",
   "metadata": {},
   "source": [
    "## 自定义回调函数\n",
    "\n",
    "MindSpore不仅有功能强大的内置回调函数，当用户有自己的特殊需求时，还可以基于`Callback`基类自定义回调函数。\n",
    "\n",
    "回调机制可以把训练过程中的重要信息记录下来，通过把一个字典类型变量`RunContext.original_args()`传递给Callback对象，使得用户可以在各个自定义的Callback中获取到相关属性，执行自定义操作，也可以自定义其他变量传递给`RunContext.original_args()`对象。\n",
    "\n",
    "`RunContext.original_args()`中的常用属性有：\n",
    "\n",
    "- loss_fn：损失函数\n",
    "- optimizer：优化器\n",
    "- train_dataset：训练的数据集\n",
    "- epoch_num：训练的epoch的数量\n",
    "- batch_num：一个epoch中step的数量\n",
    "- train_network：训练的网络\n",
    "- cur_epoch_num：当前的epoch数\n",
    "- cur_step_num：当前的step数\n",
    "- parallel_mode：并行模式\n",
    "- list_callback：所有的Callback函数\n",
    "- net_outputs：网络的输出结果\n",
    "\n",
    "通过下面两个场景，我们可以增加对自定义Callback回调函数功能的了解。\n",
    "\n",
    "1. 实现在规定时间内终止训练。用户可以设定时间阈值，当训练时间达到这个阈值后就终止训练过程。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fe844740",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin training, time is: 1646988005.0114133\n",
      "Epoch:[  0/  1],                     step:[  200/ 1875],                    loss:[0.000/0.030],                    time:6.537,                     lr:0.01000.\n",
      "Epoch:[  0/  1],                     step:[  400/ 1875],                    loss:[0.004/0.031],                    time:6.731,                     lr:0.01000.\n",
      "Epoch:[  0/  1],                     step:[  600/ 1875],                    loss:[0.007/0.033],                    time:6.998,                     lr:0.01000.\n",
      "Epoch:[  0/  1],                     step:[  800/ 1875],                    loss:[0.011/0.034],                    time:8.863,                     lr:0.01000.\n",
      "Epoch:[  0/  1],                     step:[ 1000/ 1875],                    loss:[0.018/0.034],                    time:7.650,                     lr:0.01000.\n",
      "Epoch:[  0/  1],                     step:[ 1200/ 1875],                    loss:[0.011/0.035],                    time:7.834,                     lr:0.01000.\n",
      "End training, time is: 1646988015.014049    epoch: 1  step: 1263  loss: 0.006138844\n",
      "Epoch time: 10004.156,                 per step time: 5.336,                 avg loss: 0.035\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from mindspore.train.callback import Callback\n",
    "\n",
    "# 自定义回调类\n",
    "class StopAtTime(Callback):\n",
    "    # 定义初始化过程\n",
    "    def __init__(self, run_time):\n",
    "        super(StopAtTime, self).__init__()\n",
    "        # 定义执行时间\n",
    "        self.run_time = run_time\n",
    "\n",
    "    # 开始训练时的操作\n",
    "    def begin(self, run_context):\n",
    "        cb_params = run_context.original_args()\n",
    "        # 获取当前时间戳作为开始训练时间\n",
    "        cb_params.init_time = time.time()\n",
    "        print(\"Begin training, time is:\", cb_params.init_time)\n",
    "\n",
    "    # 每个step结束后执行的操作\n",
    "    def step_end(self, run_context):\n",
    "        cb_params = run_context.original_args()\n",
    "        # 获取epoch值\n",
    "        epoch_num = cb_params.cur_epoch_num\n",
    "        # 获取step值\n",
    "        step_num = cb_params.cur_step_num\n",
    "        # 获取损失值loss\n",
    "        loss = cb_params.net_outputs\n",
    "        # 获取当前时间戳\n",
    "        cur_time = time.time()\n",
    "\n",
    "        if (cur_time - cb_params.init_time) > self.run_time:\n",
    "             # 当运行的时间大于设定的阈值时，打印信息\n",
    "            print(\"End training, time is:\", cur_time, \"   epoch:\", epoch_num, \" step:\", step_num, \" loss:\", loss)\n",
    "            # 停止训练\n",
    "            run_context.request_stop()\n",
    "\n",
    "# 开始训练\n",
    "model.train(1, dataset_train, callbacks=[LossMonitor(0.01, 200), StopAtTime(10)], dataset_sink_mode=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f0b85d5",
   "metadata": {},
   "source": [
    "从上面的打印结果可以看出，当执行到第1263个step时运行时间到达了阈值并结束了训练。\n",
    "\n",
    "2. 实现当loss小于设定的阈值时，保存ckpt文件。示例代码如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d8ead861",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint, loss:0.0000225, current step num:1085.\n",
      "Saved checkpoint, loss:0.0000291, current step num:1181.\n",
      "Saved checkpoint, loss:0.0000346, current step num:1616.\n"
     ]
    }
   ],
   "source": [
    "from mindspore import save_checkpoint\n",
    "from mindspore.train.callback import Callback\n",
    "\n",
    "# 定义保存ckpt文件的回调接口\n",
    "class SaveCallback(Callback):\n",
    "    # 定义初始化过程\n",
    "    def __init__(self, loss):\n",
    "        super(SaveCallback, self).__init__()\n",
    "        # 定义损失值阈值\n",
    "        self.loss = loss\n",
    "\n",
    "    # 定义step结束时的执行操作\n",
    "    def step_end(self, run_context):\n",
    "        cb_params = run_context.original_args()\n",
    "        # 获取当前损失值\n",
    "        cur_loss = cb_params.net_outputs.asnumpy()\n",
    "        # 如果当前损失值小于设定的阈值就停止训练\n",
    "        if cur_loss < self.loss:\n",
    "            # 自定义保存文件名\n",
    "            file_name = str(cb_params.cur_epoch_num) + \"_\" + str(cb_params.cur_step_num) + \".ckpt\"\n",
    "            # 保存网络模型\n",
    "            save_checkpoint(save_obj=cb_params.train_network, ckpt_file_name=file_name)\n",
    "            print(\"Saved checkpoint, loss:{:8.7f}, current step num:{:4}.\".format(cur_loss, cb_params.cur_step_num))\n",
    "\n",
    "# 开始训练\n",
    "model.train(1, dataset_train, callbacks=[SaveCallback(5e-5)], dataset_sink_mode=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ddb447c",
   "metadata": {},
   "source": [
    "保存目录结构如下：\n",
    "\n",
    "```text\n",
    "./\n",
    "├── 1_1085.ckpt\n",
    "├── 1_1181.ckpt\n",
    "├── 1_1616.ckpt\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MindSpore",
   "language": "python",
   "name": "mindspore"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
