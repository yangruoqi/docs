{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 数据迭代\n",
    "\n",
    "[![下载Notebook](https://gitee.com/mindspore/docs/raw/tutorials-develop/resource/_static/logo_notebook.png)](https://obs.dualstack.cn-north-4.myhuaweicloud.com/mindspore-website/notebook/tutorials-develop/tutorials/zh_cn/mindspore_iterator.ipynb)&emsp;\n",
    "[![下载样例代码](https://gitee.com/mindspore/docs/raw/tutorials-develop/resource/_static/logo_download_code.png)](https://obs.dualstack.cn-north-4.myhuaweicloud.com/mindspore-website/notebook/tutorials-develop/tutorials/zh_cn/mindspore_iterator.py)&emsp;\n",
    "[![查看源文件](https://gitee.com/mindspore/docs/raw/tutorials-develop/resource/_static/logo_source.png)](https://gitee.com/mindspore/docs/blob/tutorials-develop/tutorials/source_zh_cn/advance/dataset/iterator.ipynb)\n",
    "\n",
    "原始数据集通过数据集加载接口读取到内存，再通过数据增强操作进行数据变换，最后得到的数据集对象有两种常规的数据迭代方法：\n",
    "\n",
    "1. 创建`iterator`迭代器进行数据迭代。\n",
    "2. 数据直接传入网络模型的Model接口（如`model.train`、`model.eval`等）进行迭代训练或推理。\n",
    "\n",
    "## 创建迭代器\n",
    "\n",
    "数据集对象通常可以创建两种不同的迭代器来遍历数据，分别为：\n",
    "\n",
    "1. **元组迭代器**。创建元组迭代器的接口为`create_tuple_iterator`，通常用于`Model.train`内部使用，其迭代出来的数据可以直接用于训练。\n",
    "2. **字典迭代器**。创建字典迭代器的接口为`create_dict_iterator`，自定义`train`训练模式下，用户可以根据字典中的`key`进行进一步的数据处理操作，再输入到网络中，使用较为灵活。\n",
    "\n",
    "下面通过示例介绍两种迭代器的使用方式："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mindspore.dataset as ds\n",
    "\n",
    "# 数据集\n",
    "np_data = [[[1, 2], [3, 4]], [[5, 6], [7, 8]]]\n",
    "\n",
    "# 加载数据\n",
    "dataset = ds.NumpySlicesDataset(np_data, column_names=[\"data\"], shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "然后使用`create_tuple_iterator`或者`create_dict_iterator`创建数据迭代器。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-13T09:01:55.937317Z",
     "start_time": "2021-09-13T09:01:53.924910Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " create tuple iterator\n",
      "item:\n",
      " [[1 2]\n",
      " [3 4]]\n",
      "item:\n",
      " [[5 6]\n",
      " [7 8]]\n",
      "\n",
      " create dict iterator\n",
      "item:\n",
      " [[1 2]\n",
      " [3 4]]\n",
      "item:\n",
      " [[5 6]\n",
      " [7 8]]\n",
      "\n",
      " iterate dataset object directly\n",
      "item:\n",
      " [[1 2]\n",
      " [3 4]]\n",
      "item:\n",
      " [[5 6]\n",
      " [7 8]]\n",
      "\n",
      " iterate dataset using enumerate\n",
      "index: 0, item:\n",
      " [[1 2]\n",
      " [3 4]]\n",
      "index: 1, item:\n",
      " [[5 6]\n",
      " [7 8]]\n"
     ]
    }
   ],
   "source": [
    "# 创建元组迭代器\n",
    "print(\"\\n create tuple iterator\")\n",
    "for item in dataset.create_tuple_iterator():\n",
    "    print(\"item:\\n\", item[0])\n",
    "\n",
    "# 创建字典迭代器\n",
    "print(\"\\n create dict iterator\")\n",
    "for item in dataset.create_dict_iterator():\n",
    "    print(\"item:\\n\", item[\"data\"])\n",
    "\n",
    "# 直接遍历数据集对象（等同于创建元组迭代器）\n",
    "print(\"\\n iterate dataset object directly\")\n",
    "for item in dataset:\n",
    "    print(\"item:\\n\", item[0])\n",
    "\n",
    "# 使用enumerate方式遍历（等同于创建元组迭代器）\n",
    "print(\"\\n iterate dataset using enumerate\")\n",
    "for index, item in enumerate(dataset):\n",
    "    print(\"index: {}, item:\\n {}\".format(index, item[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果需要产生多个epoch的数据，可以相应地调整入参`num_epochs`的取值。相比于多次调用迭代器接口，直接设置epoch数可以提高数据迭代的性能。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-13T09:01:55.951495Z",
     "start_time": "2021-09-13T09:01:55.938705Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  0\n",
      "item:\n",
      " [[1 2]\n",
      " [3 4]]\n",
      "item:\n",
      " [[5 6]\n",
      " [7 8]]\n",
      "epoch:  1\n",
      "item:\n",
      " [[1 2]\n",
      " [3 4]]\n",
      "item:\n",
      " [[5 6]\n",
      " [7 8]]\n"
     ]
    }
   ],
   "source": [
    "# 创建元组迭代器产生2个epoch的数据\n",
    "epoch = 2\n",
    "\n",
    "iterator = dataset.create_tuple_iterator(num_epochs=epoch)\n",
    "\n",
    "for i in range(epoch):\n",
    "    print(\"epoch: \", i)\n",
    "    for item in iterator:\n",
    "        print(\"item:\\n\", item[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "迭代器默认输出的数据类型为`mindspore.Tensor`，如果希望得到`numpy.ndarray`类型的数据，可以设置入参`output_numpy=True`。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dtype:  <class 'mindspore.common.tensor.Tensor'> \n",
      "item:\n",
      " [[1 2]\n",
      " [3 4]]\n",
      "dtype:  <class 'mindspore.common.tensor.Tensor'> \n",
      "item:\n",
      " [[5 6]\n",
      " [7 8]]\n",
      "dtype:  <class 'numpy.ndarray'> \n",
      "item:\n",
      " [[1 2]\n",
      " [3 4]]\n",
      "dtype:  <class 'numpy.ndarray'> \n",
      "item:\n",
      " [[5 6]\n",
      " [7 8]]\n"
     ]
    }
   ],
   "source": [
    "# 默认输出类型为mindspore.Tensor\n",
    "for item in dataset.create_tuple_iterator():\n",
    "    print(\"dtype: \", type(item[0]), \"\\nitem:\\n\", item[0])\n",
    "\n",
    "# 设置输出类型为numpy.ndarray\n",
    "for item in dataset.create_tuple_iterator(output_numpy=True):\n",
    "    print(\"dtype: \", type(item[0]), \"\\nitem:\\n\", item[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下面我们通过一个拟合函数的场景，介绍在神经网络中如何使用数据迭代器，函数表达式为：$output = {x_0}\\times1 + {x_1}\\times2 + {x_2}\\times3 + {x_7}\\times8$。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------- Train ---------\n",
      "epoch:0, loss: 84.84137\n",
      "epoch:1, loss: 11.769456\n",
      "epoch:2, loss: 0.22432804\n",
      "epoch:3, loss: 1.4706595\n",
      "epoch:4, loss: 0.39552307\n",
      "epoch:5, loss: 0.8743346\n",
      "epoch:6, loss: 0.020189524\n",
      "epoch:7, loss: 0.7218361\n",
      "epoch:8, loss: 0.049575806\n",
      "epoch:9, loss: 0.05044937\n",
      "epoch:10, loss: 0.01478219\n",
      "epoch:11, loss: 0.00044083595\n",
      "epoch:12, loss: 0.009922028\n",
      "epoch:13, loss: 0.0014505386\n",
      "epoch:14, loss: 0.0048754215\n",
      "epoch:15, loss: 0.0020179749\n",
      "epoch:16, loss: 0.0010228753\n",
      "epoch:17, loss: 0.00077462196\n",
      "epoch:18, loss: 0.00025963783\n",
      "epoch:19, loss: 0.00026756525\n",
      "--------- Eval ---------\n",
      "predict: [36.06], label: [36.2]\n",
      "predict: [28.4], label: [28.2]\n",
      "predict: [21.14], label: [21.2]\n",
      "predict: [15.16], label: [15.2]\n",
      "predict: [10.21], label: [10.2]\n",
      "predict: [6.21], label: [6.2]\n",
      "predict: [3.178], label: [3.2]\n",
      "predict: [1.065], label: [1.1]\n"
     ]
    }
   ],
   "source": [
    "import mindspore.dataset as ds\n",
    "import mindspore.nn as nn\n",
    "from mindspore import Tensor\n",
    "from mindspore import amp\n",
    "from mindspore.common.initializer import Normal\n",
    "import numpy as np\n",
    "\n",
    "def func(x):\n",
    "    \"\"\"定义函数表达式\"\"\"\n",
    "    result = []\n",
    "    for sample in x:\n",
    "        total = 0\n",
    "        for i, e in enumerate(sample):\n",
    "            total += (i+1) * e\n",
    "        result.append(total)\n",
    "    return result\n",
    "\n",
    "class MyData:\n",
    "    \"\"\"自定义训练用数据集类\"\"\"\n",
    "    def __init__(self):\n",
    "        \"\"\"初始化操作\"\"\"\n",
    "        self.__data = np.array([[[1, 1, 1, 1, 1, 1, 1, 1]],\n",
    "                                [[1, 1, 1, 1, 1, 1, 1, 0]],\n",
    "                                [[1, 1, 1, 1, 1, 1, 0, 0]],\n",
    "                                [[1, 1, 1, 1, 1, 0, 0, 0]],\n",
    "                                [[1, 1, 1, 1, 0, 0, 0, 0]],\n",
    "                                [[1, 1, 1, 0, 0, 0, 0, 0]],\n",
    "                                [[1, 1, 0, 0, 0, 0, 0, 0]],\n",
    "                                [[1, 0, 0, 0, 0, 0, 0, 0]]]).astype(np.float32)\n",
    "        self.__label = np.array([func(x) for x in self.__data]).astype(np.float32)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"定义随即访问函数\"\"\"\n",
    "        return self.__data[index], self.__label[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"定义获取数据集大小函数\"\"\"\n",
    "        return len(self.__data)\n",
    "\n",
    "class MyEvalData:\n",
    "    \"\"\"自定义验证用数据集类\"\"\"\n",
    "    def __init__(self):\n",
    "        \"\"\"初始化操作\"\"\"\n",
    "        self.__data = np.array([[[1, 1.1, 1, 1, 1, 1, 1, 1]],\n",
    "                                [[1, 1.1, 1, 1, 1, 1, 1, 0]],\n",
    "                                [[1, 1.1, 1, 1, 1, 1, 0, 0]],\n",
    "                                [[1, 1.1, 1, 1, 1, 0, 0, 0]],\n",
    "                                [[1, 1.1, 1, 1, 0, 0, 0, 0]],\n",
    "                                [[1, 1.1, 1, 0, 0, 0, 0, 0]],\n",
    "                                [[1, 1.1, 0, 0, 0, 0, 0, 0]],\n",
    "                                [[1.1, 0, 0, 0, 0, 0, 0, 0]]]).astype(np.float32)\n",
    "        self.__label = np.array([func(x) for x in self.__data]).astype(np.float32)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"定义随即访问函数\"\"\"\n",
    "        return self.__data[index], self.__label[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"定义获取数据集大小函数\"\"\"\n",
    "        return len(self.__data)\n",
    "\n",
    "\n",
    "class MyNet(nn.Cell):\n",
    "    \"\"\"自定义网络\"\"\"\n",
    "    def __init__(self):\n",
    "        super(MyNet, self).__init__()\n",
    "        self.fc = nn.Dense(8, 1, weight_init=Normal(0.02))\n",
    "\n",
    "    def construct(self, x):\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"--------- Train ---------\")\n",
    "    # 训练过程\n",
    "    dataset_generator = MyData()\n",
    "    dataset = ds.GeneratorDataset(dataset_generator, [\"data\", \"label\"], shuffle=False)\n",
    "    net = MyNet()  # 定义网络\n",
    "    optimizer = nn.Momentum(net.trainable_params(), 0.01, 0.9)  # 定义优化器\n",
    "    loss = nn.MSELoss(reduction=\"mean\")  # 定义损失函数\n",
    "    train_network = amp.build_train_network(net, optimizer, loss, level=\"O3\", loss_scale_manager=None)\n",
    "    for epoch in range(20):  # 训练20次\n",
    "        for step, item in enumerate(dataset.create_dict_iterator()):\n",
    "            data = item[\"data\"]\n",
    "            label = item[\"label\"]\n",
    "            loss = train_network(data, label)\n",
    "        print(\"epoch:{}, loss: {}\".format(epoch, loss))\n",
    "\n",
    "    print(\"--------- Eval ---------\")\n",
    "    # 推理过程\n",
    "    eval_data = MyEvalData()\n",
    "    for item in eval_data:\n",
    "        predict = net(Tensor(item[0]))[0]\n",
    "        print(\"predict: {}, label: {}\".format(predict, item[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "从上面的打印结果可以看出，随着训练次数逐渐增多，损失值趋于收敛，推理结果也较为准确。\n",
    "\n",
    "> 更多关于数据迭代器的使用说明，请参考[create_tuple_iterator](https://www.mindspore.cn/docs/api/zh-CN/master/api_python/dataset/mindspore.dataset.NumpySlicesDataset.html#mindspore.dataset.NumpySlicesDataset.create_tuple_iterator) 和[create_dict_iterator](https://www.mindspore.cn/docs/api/zh-CN/master/api_python/dataset/mindspore.dataset.NumpySlicesDataset.html#mindspore.dataset.NumpySlicesDataset.create_dict_iterator)的API文档。\n",
    "\n",
    "## 数据迭代训练\n",
    "\n",
    "数据集对象创建后，可通过传入`Model`接口，由接口内部进行数据迭代，并送入网络执行训练或推理。实例代码如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-13T09:01:56.002002Z",
     "start_time": "2021-09-13T09:01:55.953018Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from mindspore import ms_function\n",
    "from mindspore import nn, Model\n",
    "import mindspore.dataset as ds\n",
    "import mindspore.ops as ops\n",
    "\n",
    "def create_dataset():\n",
    "    \"\"\"创建自定义数据集\"\"\"\n",
    "    np_data = [[[1, 2], [3, 4]], [[5, 6], [7, 8]]]\n",
    "    np_data = np.array(np_data, dtype=np.float16)\n",
    "    dataset = ds.NumpySlicesDataset(np_data, column_names=[\"data\"], shuffle=False)\n",
    "    return dataset\n",
    "\n",
    "class Net(nn.Cell):\n",
    "    \"\"\"创建一个神经网络\"\"\"\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.relu = ops.ReLU()\n",
    "        self.print = ops.Print()\n",
    "\n",
    "    @ms_function\n",
    "    def construct(self, x):\n",
    "        self.print(x)\n",
    "        return self.relu(x)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    dataset = create_dataset()\n",
    "\n",
    "    network = Net()\n",
    "    model = Model(network)\n",
    "\n",
    "    # 数据集传入model中，train接口进行数据迭代处理\n",
    "    model.train(epoch=1, train_dataset=dataset)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MindSpore",
   "language": "python",
   "name": "mindspore"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
