{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 自定义损失函数\n",
    "\n",
    "[![下载Notebook](https://gitee.com/mindspore/docs/raw/master/resource/_static/logo_notebook.png)](https://obs.dualstack.cn-north-4.myhuaweicloud.com/mindspore-website/notebook/tutorials-develop/tutorials/zh_cn/mindspore_loss.ipynb)&emsp;[![下载样例代码](https://gitee.com/mindspore/docs/raw/master/resource/_static/logo_download_code.png)](https://obs.dualstack.cn-north-4.myhuaweicloud.com/mindspore-website/notebook/tutorials-develop/tutorials/zh_cn/mindspore_loss.py)&emsp;[![查看源文件](https://gitee.com/mindspore/docs/raw/master/resource/_static/logo_source.png)](https://gitee.com/mindspore/docs/blob/tutorials-develop/tutorials/source_zh_cn/intermediate/build_net/loss.ipynb)\n",
    "\n",
    "损失函数，又叫目标函数，用于衡量预测值与真实值差异的程度。\n",
    "\n",
    "在深度学习中，模型训练就是通过不停地迭代来缩小损失函数值的过程,因此，在模型训练过程中损失函数的选择非常重要，定义一个好的损失函数，可以有效提高模型的性能。\n",
    "\n",
    "`mindspore.nn`模块中提供了许多[通用损失函数](https://www.mindspore.cn/docs/api/zh-CN/master/api_python/mindspore.nn.html#id13)，但这些通用损失函数并不适用于所有场景，很多情况需要用户自定义所需的损失函数。因此，本教程介绍如何自定义损失函数。\n",
    "\n",
    "## 内置损失函数\n",
    "\n",
    "`mindspore.nn`模块中提供了许多[通用损失函数](https://www.mindspore.cn/docs/api/zh-CN/master/api_python/mindspore.nn.html#id13)。\n",
    "\n",
    "如下示例以`nn.L1Loss`为例，计算预测值和目标值之间的平均绝对误差。\n",
    "\n",
    "`nn.L1Loss`中的参数`reduction`取值可为`mean`，`sum`，或`none`。如果 `reduction` 为`mean`或`sum`，则输出一个标量Tensor；如果`reduction`为`none`，则输出Tensor的shape为广播后的shape。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-29T03:42:22.717822Z",
     "start_time": "2021-12-29T03:42:20.636585Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import mindspore.nn as nn\n",
    "from mindspore import Tensor\n",
    "\n",
    "# 输出loss均值\n",
    "loss = nn.L1Loss()\n",
    "# 输出loss和\n",
    "loss_sum = nn.L1Loss(reduction='sum')\n",
    "# 输出loss原值\n",
    "loss_none = nn.L1Loss(reduction='none')\n",
    "\n",
    "input_data = Tensor(np.array([[1, 2, 3], [2, 3, 4]]).astype(np.float32))\n",
    "target_data = Tensor(np.array([[0, 2, 5], [3, 1, 1]]).astype(np.float32))\n",
    "\n",
    "print(\"loss:\", loss(input_data, target_data))\n",
    "print(\"loss_sum:\", loss_sum(input_data, target_data))\n",
    "print(\"loss_none:\\n\", loss_none(input_data, target_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```Text\n",
    "loss: 1.5\n",
    "loss_sum: 9.0\n",
    "loss_none:\n",
    " [[1. 0. 2.]\n",
    " [1. 2. 3.]]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 自定义损失函数\n",
    "\n",
    "自定义损失函数的方法有两种，一种是通过继承网络的基类`nn.Cell`来定义损失函数，另一种是通过继承损失函数的基类`nn.LossBase`来定义损失函数。!!!wushuiqin,两者之间有啥区别？那么用户什么场合用哪个？\n",
    "\n",
    "### 继承Cell的损失函数\n",
    "\n",
    "`nn.Cell`是MindSpore的基本网络单元，可以用于构建网络，也可以用于定义损失函数。使用`nn.Cell`定义损失函数的方法与定义一个普通的网络相同，差别在于，其执行逻辑用于计算前向网络输出与真实值之间的误差。\n",
    "\n",
    "!!!wushuiqin, 参考 https://mindspore.cn/docs/api/zh-CN/master/api_python/nn/mindspore.nn.L1Loss.html?highlight=l1loss，提供公式解释，还有结果输出解释。你写的内容比代码注释都简单。你是自定义，都不对内容进行解释，怎么自定义法。\n",
    "\n",
    "通过继承`nn.Cell`方法来定义损失函数`L1Loss`的方法如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-29T03:42:22.729232Z",
     "start_time": "2021-12-29T03:42:22.723517Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.033333335\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from mindspore import Tensor\n",
    "import mindspore.nn as nn\n",
    "import mindspore.ops as ops\n",
    "\n",
    "class L1Loss(nn.Cell):\n",
    "    \"\"\"自定义损失函数L1Loss\"\"\"\n",
    "    def __init__(self):\n",
    "        \"\"\"初始化\"\"\"\n",
    "        super(L1Loss, self).__init__()\n",
    "        self.abs = ops.Abs()\n",
    "        self.reduce_mean = ops.ReduceMean()\n",
    "\n",
    "    def construct(self, base, target):\n",
    "        \"\"\"调用算子\"\"\"\n",
    "        x = self.abs(base - target)\n",
    "        return self.reduce_mean(x)\n",
    "\n",
    "loss = L1Loss()\n",
    "# 生成预测值\n",
    "input_data = Tensor(np.array([0.1, 0.2, 0.3]).astype(np.float32))\n",
    "# 生成真实值\n",
    "target_data = Tensor(np.array([0.1, 0.2, 0.2]).astype(np.float32))\n",
    "\n",
    "output = loss(input_data, target_data)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 继承LossBase的损失函数\n",
    "\n",
    "通过继承[nn.LossBase(reduction='mean')](https://www.mindspore.cn/docs/api/zh-CN/master/api_python/nn/mindspore.nn.LossBase.html#mindspore.nn.LossBase)来定义损失函数`L1Loss`，与`nn.Cell`类似，都要重写`__init__`方法和`construct`方法。\n",
    "\n",
    "`nn.LossBase`可使用方法`get_loss`将`reduction`应用于损失计算，其中`reduction`的合法参数有三个：`mean`（求均值）、`sum`（求均值）和`none`（出原值）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-29T03:42:22.766767Z",
     "start_time": "2021-12-29T03:42:22.759510Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.033333335\n"
     ]
    }
   ],
   "source": [
    "class L1Loss(nn.LossBase):\n",
    "    def __init__(self, reduction=\"mean\"):\n",
    "        \"\"\"初始化并求loss均值\"\"\"\n",
    "        super(L1Loss, self).__init__(reduction)\n",
    "        # 求绝对值\n",
    "        self.abs = ops.Abs()\n",
    "\n",
    "    def construct(self, base, target):\n",
    "        x = self.abs(base - target)\n",
    "        # 返回loss均值\n",
    "        return self.get_loss(x)\n",
    "\n",
    "loss = L1Loss()\n",
    "# 生成预测值\n",
    "input_data = Tensor(np.array([0.1, 0.2, 0.3]).astype(np.float32))\n",
    "# 生成真实值\n",
    "target_data = Tensor(np.array([0.1, 0.2, 0.2]).astype(np.float32))\n",
    "\n",
    "output = loss(input_data, target_data)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 损失函数与模型训练\n",
    "\n",
    "自定义的损失函数`L1Loss`完成后，可使用MindSpore的接口[Model](https://www.mindspore.cn/docs/api/zh-CN/master/api_python/mindspore/mindspore.Model.html#mindspore.Model)中`train`接口进行模型训练，定义`Model`时需要指定前向网络、损失函数和优化器，`Model`内部会将它们关联起来，组成一张训练网络。\n",
    "\n",
    "在`Model`中，前向网络和损失函数是通过[nn.WithLossCell](https://www.mindspore.cn/docs/api/zh-CN/master/api_python/nn/mindspore.nn.WithLossCell.html#mindspore.nn.WithLossCell)关联起来的，`nn.WithLossCell`支持两个输入，分别为`data`和`label`。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-29T03:42:23.488075Z",
     "start_time": "2021-12-29T03:42:23.312491Z"
    }
   },
   "outputs": [],
   "source": [
    "from mindspore import Model\n",
    "from mindspore import dataset as ds\n",
    "from mindspore.nn import LossBase\n",
    "from mindspore.common.initializer import Normal\n",
    "from mindspore.train.callback import LossMonitor\n",
    "\n",
    "# 生成数据及对应标签\n",
    "def get_data(num, w=2.0, b=3.0):\n",
    "    for _ in range(num):\n",
    "        x = np.random.uniform(-10.0, 10.0)\n",
    "        noise = np.random.normal(0, 1)\n",
    "        y = x * w + b + noise\n",
    "        yield np.array([x]).astype(np.float32), np.array([y]).astype(np.float32)\n",
    "\n",
    "# 加载数据集\n",
    "def create_dataset(num_data, batch_size=16):\n",
    "    dataset = ds.GeneratorDataset(list(get_data(num_data)), column_names=['data', 'label'])\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    return dataset\n",
    "\n",
    "# 定义线性回归网络\n",
    "class LinearNet(nn.Cell):\n",
    "    def __init__(self):\n",
    "        super(LinearNet, self).__init__()\n",
    "        self.fc = nn.Dense(1, 1, Normal(0.02), Normal(0.02))\n",
    "\n",
    "    def construct(self, x):\n",
    "        return self.fc(x)\n",
    "\n",
    "# 通过继承LossBase来定义损失函数\n",
    "class L1Loss(LossBase):\n",
    "    def __init__(self, reduction=\"mean\"):\n",
    "        \"\"\"初始化，求loss均值\"\"\"\n",
    "        super(L1Loss, self).__init__(reduction)\n",
    "        # 求绝对值\n",
    "        self.abs = ops.Abs()\n",
    "\n",
    "    def construct(self, base, target):\n",
    "        x = self.abs(base - target)\n",
    "        # 返回loss均值\n",
    "        return self.get_loss(x)\n",
    "\n",
    "# 创建数据集\n",
    "ds_train = create_dataset(num_data=160)\n",
    "# 定义网络\n",
    "net = LinearNet()\n",
    "# 定义损失函数\n",
    "loss = L1Loss()\n",
    "# 定义优化器\n",
    "opt = nn.Momentum(net.trainable_params(), learning_rate=0.005, momentum=0.9)\n",
    "# 定义model，使用model接口将网络、损失函数和优化器关联起来\n",
    "model = Model(net, loss, opt)\n",
    "# 模型训练\n",
    "model.train(epoch=1, train_dataset=ds_train, callbacks=[LossMonitor()], dataset_sink_mode=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```Text\n",
    "epoch: 1 step: 1, loss is 11.8941\n",
    "epoch: 1 step: 2, loss is 10.38729\n",
    "epoch: 1 step: 3, loss is 11.357301\n",
    "epoch: 1 step: 4, loss is 8.294586\n",
    "epoch: 1 step: 5, loss is 8.940672\n",
    "epoch: 1 step: 6, loss is 8.314494\n",
    "epoch: 1 step: 7, loss is 8.400087\n",
    "epoch: 1 step: 8, loss is 8.68959\n",
    "epoch: 1 step: 9, loss is 8.185644\n",
    "epoch: 1 step: 10, loss is 7.140411\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 多标签损失函数与模型训练\n",
    "\n",
    "上述定义了一个简单的平均绝对误差损失函数`L1Loss`，但许多深度学习应用的数据集较复杂，例如目标检测网络Faster R-CNN的数据中就包含多个标签，而不是简单的一个数据对应一个标签，这时候损失函数的定义和使用略有不同。\n",
    "\n",
    "本节介绍在多标签数据集场景下，如何定义多标签损失函数（Multi label loss function），并使用Model进行模型训练。\n",
    "\n",
    "### 多标签数据集\n",
    "\n",
    "!!! zhaoyu，进阶数据集中多一章自定义数据集，把入门的自定义数据集挪进来，也把多标签数据集挪进来。\n",
    "\n",
    "!!! zhaoyu ,shuiqin, 补充下面代码的公式$x * w + b + noise1$和功能解释。\n",
    "\n",
    "如下示例通过`get_multilabel_data`函数产生一组数据`x`对应两个标签`y1`和`y2`，并将`GeneratorDataset`中的`column_names`参数设置为['data', 'label1', 'label2']，这个通过函数`create_multilabel_dataset`产生的数据集就有一个数据`data`对应两个标签`label1`和`label2`。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from mindspore import dataset as ds\n",
    "\n",
    "def get_multilabel_data(num, w=2.0, b=3.0):\n",
    "    for _ in range(num):\n",
    "        x = np.random.uniform(-10.0, 10.0)\n",
    "        noise1 = np.random.normal(0, 1)\n",
    "        noise2 = np.random.normal(-1, 1)\n",
    "        y1 = x * w + b + noise1\n",
    "        y2 = x * w + b + noise2\n",
    "        yield np.array([x]).astype(np.float32), np.array([y1]).astype(np.float32), np.array([y2]).astype(np.float32)\n",
    "\n",
    "def create_multilabel_dataset(num_data, batch_size=16):\n",
    "    dataset = ds.GeneratorDataset(list(get_multilabel_data(num_data)), column_names=['data', 'label1', 'label2'])\n",
    "    # 每个batch有16个数据\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 多标签损失函数\n",
    "\n",
    "针对上一步创建的多标签数据集，定义多标签损失函数`L1LossForMultiLabel`。\n",
    "\n",
    "在`L1LossForMultiLabel`中的`construct`方法的输入有三个，预测值`base`，真实值`target1`和`target2`，我们在`construct`中分别计算预测值与真实值`target1`，预测值与真实值`target2`之间的误差，将这两个误差的均值作为最终的损失函数值.\n",
    "\n",
    "!!!wushuiqin,给出公式和对应的解释。\n",
    "\n",
    "示例代码如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class L1LossForMultiLabel(LossBase):\n",
    "    def __init__(self, reduction=\"mean\"):\n",
    "        super(L1LossForMultiLabel, self).__init__(reduction)\n",
    "        self.abs = ops.Abs()\n",
    "\n",
    "    def construct(self, base, target1, target2):\n",
    "        x1 = self.abs(base - target1)\n",
    "        x2 = self.abs(base - target2)\n",
    "        return self.get_loss(x1)/2 + self.get_loss(x2)/2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 多标签模型训练\n",
    "\n",
    "使用`Model`关联指定的前向网络、损失函数和优化器时，由于`Model`默认使用的`nn.WithLossCell`只有两个输入：`data`和`label`，不适用于多标签的场景。\n",
    "\n",
    "在多标签场景下，如果想使用`Model`进行模型训练就需要将前向网络与多标签损失函数连接起来，需要自定义损失网络，将前向网络和自定义多标签损失函数关联起来。\n",
    "\n",
    "- 定义损失网络\n",
    "\n",
    "定义损失网络`CustomWithLossCell`，其中`__init__`方法的输入分别为前向网络`backbone`和损失函数`loss_fn`，`construct`方法的输入分别为数据`data`、`label1`和`label2`，将数据部分`data`传给前向网络`backend`，将预测值和两个标签传给损失函数`loss_fn`。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomWithLossCell(nn.Cell):\n",
    "    def __init__(self, backbone, loss_fn):\n",
    "        super(CustomWithLossCell, self).__init__(auto_prefix=False)\n",
    "        self._backbone = backbone\n",
    "        self._loss_fn = loss_fn\n",
    "\n",
    "    def construct(self, data, label1, label2):\n",
    "        output = self._backbone(data)\n",
    "        return self._loss_fn(output, label1, label2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 定义网络模型并训练\n",
    "\n",
    "使用Model连接前向网络、多标签损失函数和优化器时，`Model`的网络`network`指定为自定义的损失网络`loss_net`，损失函数`loss_fn`不指定，优化器仍使用`Momentum`。\n",
    "\n",
    "由于未指定`loss_fn`，`Model`则认为`network`内部已经实现了损失函数的逻辑，不会用`nn.WithLossCell`对前向函数和损失函数进行封装。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-29T03:42:24.079033Z",
     "start_time": "2021-12-29T03:42:23.851418Z"
    }
   },
   "outputs": [],
   "source": [
    "# 创建多标签数据集\n",
    "ds_train = create_multilabel_dataset(num_data=160)\n",
    "# 定义网络\n",
    "net = LinearNet()\n",
    "# 定义多标签损失函数\n",
    "loss = L1LossForMultiLabel()\n",
    "# 定义损失网络，连接前向网络和多标签损失函数\n",
    "loss_net = CustomWithLossCell(net, loss)\n",
    "# 定义优化器\n",
    "opt = nn.Momentum(net.trainable_params(), learning_rate=0.005, momentum=0.9)\n",
    "# 定义Model，多标签场景下Model无需指定损失函数\n",
    "model = Model(network=loss_net, optimizer=opt)\n",
    "# 模型训练\n",
    "model.train(epoch=1, train_dataset=ds_train, callbacks=[LossMonitor()], dataset_sink_mode=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```Text\n",
    "epoch: 1 step: 1, loss is 10.959082\n",
    "epoch: 1 step: 2, loss is 13.167221\n",
    "epoch: 1 step: 3, loss is 10.139606\n",
    "epoch: 1 step: 4, loss is 8.816353\n",
    "epoch: 1 step: 5, loss is 7.9143906\n",
    "epoch: 1 step: 6, loss is 6.767868\n",
    "epoch: 1 step: 7, loss is 7.972429\n",
    "epoch: 1 step: 8, loss is 7.185155\n",
    "epoch: 1 step: 9, loss is 6.67676\n",
    "epoch: 1 step: 10, loss is 5.129463\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "本章节简单讲解了多标签数据集场景下，如何定义损失函数并使用Model进行模型训练。在很多其他场景中，也可以采用此类方法进行模型训练。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MindSpore",
   "language": "python",
   "name": "mindspore"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
