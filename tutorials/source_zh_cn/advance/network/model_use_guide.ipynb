{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model基本使用\n",
    "\n",
    "[![下载Notebook](https://gitee.com/mindspore/docs/raw/master/resource/_static/logo_notebook.png)](https://obs.dualstack.cn-north-4.myhuaweicloud.com/mindspore-website/notebook/tutorials-develop/tutorials/zh_cn/mindspore_model_use_guide.ipynb)&emsp;[![下载样例代码](https://gitee.com/mindspore/docs/raw/master/resource/_static/logo_download_code.png)](https://obs.dualstack.cn-north-4.myhuaweicloud.com/mindspore-website/notebook/tutorials-develop/tutorials/zh_cn/mindspore_model_use_guide.py)&emsp;[![查看源文件](https://gitee.com/mindspore/docs/raw/master/resource/_static/logo_source.png)](https://gitee.com/mindspore/docs/blob/tutorials-develop/tutorials/source_zh_cn/advance/network/model_use_guide.ipynb)\n",
    "\n",
    "通常情况下，定义训练和评估网络并直接运行，已经可以满足基本需求，但仍然建议通过`Model`来进行模型训练和评估。一方面，`Model`可以在一定程度上简化代码。例如：无需手动遍历数据集；在不需要自定义`nn.TrainOneStepCell`的场景下，可以借助`Model`自动构建训练网络；可以使用`Model`的`eval`接口进行模型评估，直接输出评估结果，无需手动调用评价指标的`clear`、`update`、`eval`函数等。另一方面，`Model`提供了很多高阶功能，如数据下沉、混合精度等，在不借助`Model`的情况下，使用这些功能需要花费较多的时间仿照`Model`进行自定义。\n",
    "\n",
    "本文档首先对Model进行基本介绍，然后重点讲解如何使用`Model`进行模型训练、评估和推理。\n",
    "\n",
    "## Model基本介绍\n",
    "\n",
    "[Model](https://mindspore.cn/docs/api/zh-CN/master/api_python/mindspore/mindspore.Model.html#mindspore.Model)是MindSpore提供的高阶API，可以进行模型训练、评估和推理。`Model`接口的常用参数如下：\n",
    "\n",
    "- `network`：用于训练或推理的神经网络。\n",
    "- `loss_fn`：所使用的损失函数。\n",
    "- `optimizer`：所使用的优化器。\n",
    "- `metrics`：用于模型评估的一组评价函数，在不需要模型评估时使用默认值`None`。\n",
    "- `eval_network`：模型评估所使用的网络，未定义情况下，`Model`会使用`networ`和`loss_fn`封装一个`eval_network`。默认值为`None`。\n",
    "- `eval_indexes`：在定义`eval_network`的情况下使用。如果`eval_indexes`为默认值`None`，`Model`会将`eval_network`的所有输出传给 `metrics`。如果配置`eval_indexes`，必须包含三个元素，分别为损失值、预测值和标签在`eval_network`输出中的位置，此时，损失值将传给损失评价函数，预测值和标签将传给其他评价函数。推荐使用评价函数的`mindspore.nn.Metric.set_indexes`代替`eval_indexes`。默认值为`None`。\n",
    "\n",
    "`Model`提供了以下接口用于模型训练、评估和推理：\n",
    "\n",
    "- `train`：用于在训练集上进行模型训练。\n",
    "- `eval`：用于在验证集上进行模型评估。\n",
    "- `predict`：用于对输入的一组数据进行推理，输出预测结果。\n",
    "\n",
    "## 模型训练、评估和推理\n",
    "\n",
    "对于简单场景的神经网络，可以在定义`Model`时指定前向网络`network`、损失函数`loss_fn`、优化器`optimizer`和评价函数`metrics`。此时，`Model`会使用`network`作为前向网络，并使用`nn.WithLossCell`和`nn.TrainOneStepCell`构建训练网络，使用`nn.WithEvalCell`构建评估网络。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-04T06:43:30.392367Z",
     "start_time": "2022-01-04T06:43:28.436687Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import mindspore.dataset as ds\n",
    "import mindspore.nn as nn\n",
    "from mindspore import Model\n",
    "from mindspore.common.initializer import Normal\n",
    "\n",
    "\n",
    "def get_data(num, w=2.0, b=3.0):\n",
    "    \"\"\"生成样本数据及对应的标签\"\"\"\n",
    "    for _ in range(num):\n",
    "        x = np.random.uniform(-10.0, 10.0)\n",
    "        noise = np.random.normal(0, 1)\n",
    "        y = x * w + b + noise\n",
    "        yield np.array([x]).astype(np.float32), np.array([y]).astype(np.float32)\n",
    "\n",
    "\n",
    "def create_dataset(num_data, batch_size=16):\n",
    "    \"\"\"生成数据集\"\"\"\n",
    "    dataset = ds.GeneratorDataset(list(get_data(num_data)), column_names=['data', 'label'])\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    return dataset\n",
    "\n",
    "\n",
    "class LinearNet(nn.Cell):\n",
    "    \"\"\"定义线性回归网络\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc = nn.Dense(1, 1, Normal(0.02), Normal(0.02))\n",
    "\n",
    "    def construct(self, x):\n",
    "        return self.fc(x)\n",
    "\n",
    "\n",
    "# 创建训练数据集\n",
    "train_dataset = create_dataset(num_data=160)\n",
    "# 构建前向网络\n",
    "net = LinearNet()\n",
    "# 设定损失函数\n",
    "crit = nn.MSELoss()\n",
    "# 设定优化器\n",
    "opt = nn.Momentum(net.trainable_params(), learning_rate=0.005, momentum=0.9)\n",
    "# 设定评价指标\n",
    "metrics = {\"mae\"}\n",
    "# 使用Model构建训练网络\n",
    "model = Model(network=net, loss_fn=crit, optimizer=opt, metrics=metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 模型训练\n",
    "\n",
    "使用`train`接口执行模型训练，`train`接口参数如下：\n",
    "\n",
    "- `epoch`：训练执行轮次。通常每个epoch都会使用全量数据集进行训练。当`dataset_sink_mode`设置为True且`sink_size`大于零时，则每个`epoch`训练次数为`sink_size`而不是数据集的总步数。\n",
    "- `train_dataset`：一个训练数据集迭代器。如果定义了`loss_fn`，则数据和标签会被分别传给`network`和`loss_fn`，此时数据集需要返回一个元组（data, label）。如果数据集中有多个数据或者标签，可以设置`loss_fn`为None，并在`network`中实现损失函数计算，此时数据集返回的所有数据组成的元组（data1, data2, data3, …）会传给`network`。\n",
    "- `callbacks`：训练过程中需要执行的回调对象或者回调对象列表。默认值为None。\n",
    "- `dataset_sink_mode`：数据是否直接下沉至处理器进行处理。使用PYNATIVE_MODE模式或CPU处理器时，模型训练流程将以非下沉模式执行。默认值为True。\n",
    "- `sink_size`：控制每次数据下沉的数据量。`dataset_sink_mode`为False时`sink_size`无效。如果sink_size=-1，则每一次epoch下沉完整数据集。如果sink_size>0，则每一次epoch下沉数据量为sink_size的数据集。默认值为-1。\n",
    "\n",
    "如下示例使用`train`接口执行模型训练，通过`LossMonitor`回调函数查看在训练过程中的损失函数值。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-04T06:43:30.952190Z",
     "start_time": "2022-01-04T06:43:30.525149Z"
    }
   },
   "outputs": [],
   "source": [
    "from mindspore.train.callback import LossMonitor\n",
    "\n",
    "# 模型训练\n",
    "epochs = 2\n",
    "model.train(epochs, train_dataset, callbacks=[LossMonitor()], dataset_sink_mode=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```Text\n",
    "epoch: 1 step: 1, loss is 111.50298\n",
    "epoch: 1 step: 2, loss is 79.41924\n",
    "epoch: 1 step: 3, loss is 24.844707\n",
    "epoch: 1 step: 4, loss is 31.563843\n",
    "epoch: 1 step: 5, loss is 84.5044\n",
    "epoch: 1 step: 6, loss is 76.74334\n",
    "epoch: 1 step: 7, loss is 59.548176\n",
    "epoch: 1 step: 8, loss is 14.567602\n",
    "epoch: 1 step: 9, loss is 9.064165\n",
    "epoch: 1 step: 10, loss is 36.3915\n",
    "epoch: 2 step: 1, loss is 52.73662\n",
    "epoch: 2 step: 2, loss is 47.76719\n",
    "epoch: 2 step: 3, loss is 27.069574\n",
    "epoch: 2 step: 4, loss is 3.3497584\n",
    "epoch: 2 step: 5, loss is 15.301208\n",
    "epoch: 2 step: 6, loss is 36.09889\n",
    "epoch: 2 step: 7, loss is 36.04988\n",
    "epoch: 2 step: 8, loss is 15.2287655\n",
    "epoch: 2 step: 9, loss is 4.360796\n",
    "epoch: 2 step: 10, loss is 4.1171966\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 模型评估\n",
    "\n",
    "使用`eval`接口进行评估，`eval`接口参数如下：\n",
    "\n",
    "- `valid_dataset`：评估模型的数据集。\n",
    "- `callbacks`：评估过程中需要执行的回调对象或回调对象列表，默认值为None。\n",
    "- `dataset_sink_mode`：数据是否直接下沉至处理器进行处理，默认值为True。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-04T06:43:31.009605Z",
     "start_time": "2022-01-04T06:43:30.954322Z"
    }
   },
   "outputs": [],
   "source": [
    "# 创建评估数据集\n",
    "eval_dataset = create_dataset(num_data=80)\n",
    "# 执行模型评估\n",
    "eval_result = model.eval(eval_dataset)\n",
    "# 打印评估结果\n",
    "print(eval_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```Text\n",
    "{'mae': 9.021200180053711}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 模型推理\n",
    "\n",
    "使用`predict`接口进行推理，`predict`接口参数如下：\n",
    "\n",
    "- `predict_data`：预测样本，数据可以是单个张量、张量列表或张量元组。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-04T06:43:31.042129Z",
     "start_time": "2022-01-04T06:43:31.011659Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 6.436742 ]\n",
      " [12.195116 ]\n",
      " [-5.655384 ]\n",
      " [-7.1004953]\n",
      " [14.370203 ]\n",
      " [ 2.819644 ]\n",
      " [ 3.2866564]\n",
      " [ 4.150859 ]\n",
      " [ 6.0963335]\n",
      " [10.560071 ]\n",
      " [ 3.7434154]\n",
      " [-6.2176857]\n",
      " [ 7.619314 ]\n",
      " [-2.344999 ]\n",
      " [13.424776 ]\n",
      " [ 3.5336251]]\n"
     ]
    }
   ],
   "source": [
    "for d in eval_dataset.create_dict_iterator():\n",
    "    data = d[\"data\"]\n",
    "    break\n",
    "\n",
    "# 执行模型预测\n",
    "output = model.predict(data)\n",
    "# 打印预测结果\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "一般情况下需要对推理结果进行后处理才能得到比较直观的推理结果。与自定义训练和推理网络不同，使用Model进行模型训练、推理和评估时，不需要`set_train`配置网络的执行模式。\n",
    "\n",
    "## 自定义场景的Model应用\n",
    "\n",
    "MindSpore提供的网络封装函数`nn.WithLossCell`、`nn.TrainOneStepCell`和`nn.WithEvalCell`并不适用于所有场景，实际场景中常常需要自定义网络的封装函数，这种情况下`Model`使用这些封装函数自动地进行封装显然是不合理的。接下来介绍在自定义网络封装函数时如何正确地使用`Model`。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 自定义损失网络\n",
    "\n",
    "在有多个数据或者多个标签的场景下，可以使用自定义损失网络将前向网络和自定义的损失函数链接起来作为`Model`的`network`，`loss_fn`使用默认值`None`，此时`Model`内部不会经过`nn.WithLossCell`，而会直接使用`nn.TrainOneStepCell`将`network`与`optimizer`组成训练网络。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-04T06:43:31.051039Z",
     "start_time": "2022-01-04T06:43:31.043718Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import mindspore.dataset as ds\n",
    "import mindspore.ops as ops\n",
    "import mindspore.nn as nn\n",
    "from mindspore import Model\n",
    "from mindspore.nn import LossBase\n",
    "from mindspore.train.callback import LossMonitor\n",
    "\n",
    "\n",
    "def get_multilabel_data(num, w=2.0, b=3.0):\n",
    "    \"\"\"生成多标签数据，产生一组数据x对应两个标签y1和y2\"\"\"\n",
    "    for _ in range(num):\n",
    "        x = np.random.uniform(-10.0, 10.0)\n",
    "        noise1 = np.random.normal(0, 1)\n",
    "        noise2 = np.random.normal(-1, 1)\n",
    "        y1 = x * w + b + noise1\n",
    "        y2 = x * w + b + noise2\n",
    "        yield np.array([x]).astype(np.float32), np.array([y1]).astype(np.float32), np.array([y2]).astype(np.float32)\n",
    "\n",
    "\n",
    "def create_multilabel_dataset(num_data, batch_size=16):\n",
    "    \"\"\"生成多标签数据集，一个数据data对应两个标签label1和label2\"\"\"\n",
    "    dataset = ds.GeneratorDataset(list(get_multilabel_data(num_data)), column_names=['data', 'label1', 'label2'])\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    return dataset\n",
    "\n",
    "\n",
    "class LinearNet(nn.Cell):\n",
    "    \"\"\"定义线性回归网络\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc = nn.Dense(1, 1, Normal(0.02), Normal(0.02))\n",
    "\n",
    "    def construct(self, x):\n",
    "        return self.fc(x)\n",
    "\n",
    "\n",
    "class L1LossForMultiLabel(LossBase):\n",
    "    \"\"\"自定义多标签损失函数\"\"\"\n",
    "\n",
    "    def __init__(self, reduction=\"mean\"):\n",
    "        super(L1LossForMultiLabel, self).__init__(reduction)\n",
    "        self.abs = ops.Abs()\n",
    "\n",
    "    def construct(self, base, target1, target2):\n",
    "        \"\"\"输入有三个，分别为预测值base，真实值target1和target2\"\"\"\n",
    "        x1 = self.abs(base - target1)\n",
    "        x2 = self.abs(base - target2)\n",
    "        return self.get_loss(x1) / 2 + self.get_loss(x2) / 2\n",
    "\n",
    "\n",
    "class CustomWithLossCell(nn.Cell):\n",
    "    \"\"\"连接前向网络和损失函数\"\"\"\n",
    "\n",
    "    def __init__(self, backbone, loss_fn):\n",
    "        \"\"\"输入有两个，前向网络backbone和损失函数loss_fn\"\"\"\n",
    "        super(CustomWithLossCell, self).__init__(auto_prefix=False)\n",
    "        self._backbone = backbone\n",
    "        self._loss_fn = loss_fn\n",
    "\n",
    "    def construct(self, data, label1, label2):\n",
    "        output = self._backbone(data)  # 前向计算得到网络输出\n",
    "        return self._loss_fn(output, label1, label2)  # 得到多标签损失值\n",
    "\n",
    "\n",
    "# 创建多标签数据集\n",
    "multi_train_dataset = create_multilabel_dataset(num_data=160)\n",
    "# 构建线性回归网络\n",
    "net = LinearNet()\n",
    "# 多标签损失函数\n",
    "loss = L1LossForMultiLabel()\n",
    "# 连接线性回归网络和多标签损失函数\n",
    "loss_net = CustomWithLossCell(net, loss)\n",
    "# 定义优化器\n",
    "opt = nn.Momentum(net.trainable_params(), learning_rate=0.005, momentum=0.9)\n",
    "# 使用Model连接网络和优化器，此时Model内部不经过nn.WithLossCell\n",
    "model = Model(network=loss_net, optimizer=opt)\n",
    "# 使用train接口进行模型训练\n",
    "model.train(epoch=1, train_dataset=multi_train_dataset, callbacks=[LossMonitor()], dataset_sink_mode=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```Text\n",
    "epoch: 1 step: 1, loss is 9.000354\n",
    "epoch: 1 step: 2, loss is 9.808951\n",
    "epoch: 1 step: 3, loss is 11.241606\n",
    "epoch: 1 step: 4, loss is 7.979822\n",
    "epoch: 1 step: 5, loss is 7.6575403\n",
    "epoch: 1 step: 6, loss is 9.43737\n",
    "epoch: 1 step: 7, loss is 8.86912\n",
    "epoch: 1 step: 8, loss is 8.786628\n",
    "epoch: 1 step: 9, loss is 6.342721\n",
    "epoch: 1 step: 10, loss is 8.242945\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 自定义训练网络\n",
    "\n",
    "在自定义训练网络时，需要手动构建训练网络作为`Model`的`network`，`loss_fn`和`optimizer`均使用默认值`None`，此时`Model`会使用`network`作为训练网络，而不会进行任何封装。如下示例自定义训练网络`CustomTrainOneStepCell`，然后通过`Model`接口构建训练网络。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mindspore.ops as ops\n",
    "from mindspore.context import get_auto_parallel_context, ParallelMode\n",
    "from mindspore import Model\n",
    "from mindspore.train.callback import LossMonitor\n",
    "\n",
    "\n",
    "class CustomTrainOneStepCell(nn.Cell):\n",
    "    \"\"\"自定义训练网络\"\"\"\n",
    "\n",
    "    def __init__(self, network, optimizer, sens=1.0):\n",
    "        \"\"\"入参有三个：训练网络，优化器和反向传播缩放比例\"\"\"\n",
    "        super(CustomTrainOneStepCell, self).__init__(auto_prefix=False)\n",
    "        self.network = network  # 前向网络\n",
    "        self.network.set_grad()  # 构建用于计算梯度的反向网络\n",
    "        self.optimizer = optimizer  # 优化器\n",
    "        self.weights = self.optimizer.parameters  # 待更新的参数\n",
    "        self.grad = ops.GradOperation(get_by_list=True, sens_param=True)  # 进行方向传播获取梯度\n",
    "        self.sens = sens  # 网络输出的缩放比\n",
    "        self.reducer_flag = False\n",
    "        self.grad_reducer = ops.identity\n",
    "        self.parallel_mode = get_auto_parallel_context(\"parallel_mode\")  # 获取并行模式\n",
    "        self.reducer_flag = self.parallel_mode in (ParallelMode.DATA_PARALLEL, ParallelMode.HYBRID_PARALLEL)\n",
    "        if self.reducer_flag:  # 若并行模式为数据并行或手动实现数据并行和模型并行\n",
    "            self.mean = get_auto_parallel_context(\"gradients_mean\")\n",
    "            self.degree = get_auto_parallel_context(\"device_num\")  # 获取设备可用的编号\n",
    "            # 用于在分布式场景下进行梯度广播，单机单卡不需要使用\n",
    "            self.grad_reducer = nn.DistributedGradReducer(self.weights, self.mean, self.degree)\n",
    "\n",
    "    def construct(self, *inputs):\n",
    "        loss = self.network(*inputs)  # 执行前向网络，计算当前输入的损失函数值\n",
    "        sens = ops.fill(loss.dtype, loss.shape, self.sens)  # 对损失值执行缩放\n",
    "        grads = self.grad(self.network, self.weights)(*inputs, sens)  # 进行反向传播，计算梯度\n",
    "        grads = self.grad_reducer(grads)  # 在分布式情况下进行梯度广播，单机单卡时直接返回输入梯度\n",
    "        loss = ops.depend(loss, self.optimizer(grads))  # 使用优化器更新梯度\n",
    "        return loss  # 返回损失值\n",
    "\n",
    "\n",
    "# 创建训练数据集\n",
    "multi_train_ds = create_multilabel_dataset(num_data=160)\n",
    "# 手动构建训练网络\n",
    "train_net = CustomTrainOneStepCell(loss_net, opt)\n",
    "# 构建训练网络\n",
    "model = Model(train_net)\n",
    "# 执行模型训练\n",
    "model.train(epoch=1, train_dataset=multi_train_ds, callbacks=[LossMonitor()], dataset_sink_mode=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```Text\n",
    "epoch: 1 step: 1, loss is 4.752144\n",
    "epoch: 1 step: 2, loss is 3.7447517\n",
    "epoch: 1 step: 3, loss is 3.6886137\n",
    "epoch: 1 step: 4, loss is 3.360796\n",
    "epoch: 1 step: 5, loss is 2.8157845\n",
    "epoch: 1 step: 6, loss is 2.733788\n",
    "epoch: 1 step: 7, loss is 2.7561996\n",
    "epoch: 1 step: 8, loss is 2.2559843\n",
    "epoch: 1 step: 9, loss is 2.6331482\n",
    "epoch: 1 step: 10, loss is 3.1449673\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 自定义评估网络\n",
    "\n",
    "`Model`默认使用`nn.WithEvalCell`构建评估网络，在不满足需求的情况下需要手动构建评估网络，如多数据和多标签场景下。如下示例自定义评估网络`CustomWithEvalCell`，然后使用`Model`接口构建评估网络。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-04T06:43:31.373188Z",
     "start_time": "2022-01-04T06:43:31.369046Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mae1': 3.2365811824798585, 'mae2': 2.774002695083618}\n"
     ]
    }
   ],
   "source": [
    "import mindspore.nn as nn\n",
    "from mindspore.train.callback import LossMonitor\n",
    "from mindspore import Model\n",
    "\n",
    "\n",
    "class CustomWithEvalCell(nn.Cell):\n",
    "    \"\"\"自定义多标签评估网络\"\"\"\n",
    "\n",
    "    def __init__(self, network):\n",
    "        super(CustomWithEvalCell, self).__init__(auto_prefix=False)\n",
    "        self.network = network\n",
    "\n",
    "    def construct(self, data, label1, label2):\n",
    "        output = self.network(data)\n",
    "        return output, label1, label2\n",
    "\n",
    "\n",
    "# 构建多标签评估数据集\n",
    "multi_eval_dataset = create_multilabel_dataset(num_data=80)\n",
    "# 构建评估网络\n",
    "eval_net = CustomWithEvalCell(net)\n",
    "# 评估函数\n",
    "mae1 = nn.MAE()\n",
    "mae2 = nn.MAE()\n",
    "mae1.set_indexes([0, 1])\n",
    "mae2.set_indexes([0, 2])\n",
    "# 使用Model构建评估网络\n",
    "model = Model(network=loss_net, optimizer=opt, eval_network=eval_net, metrics={\"mae1\": mae1, \"mae2\": mae2})\n",
    "# 执行模型评估\n",
    "result = model.eval(multi_eval_dataset, dataset_sink_mode=False)\n",
    "# 打印评估结果\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上述代码在进行模型评估时，评估网络的输出会透传给评估指标的`update`函数，也就是说，`update`函数将接收到三个输入，分别为`logits`、`label1`和`label2`。`nn.MAE`仅允许在两个输入上计算评价指标，因此使用`set_indexes`指定`mae1`使用下标为0和1的输入，也就是`logits`和`label1`，计算评估结果；指定`mae2`使用下标为0和2的输入，也就是`logits`和`label2`，计算评估结果。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 推理\n",
    "\n",
    "   `Model`没有提供用于指定自定义推理网络的参数，此时可以直接运行前向网络获得推理结果。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-04T06:43:31.481326Z",
     "start_time": "2022-01-04T06:43:31.449243Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ -6.0416026 ]\n",
      " [-11.769779  ]\n",
      " [ -5.366366  ]\n",
      " [  4.769652  ]\n",
      " [ 15.140262  ]\n",
      " [-12.409686  ]\n",
      " [ -4.4211154 ]\n",
      " [ -9.712878  ]\n",
      " [-22.129475  ]\n",
      " [  1.0024961 ]\n",
      " [ -8.859579  ]\n",
      " [  1.7755286 ]\n",
      " [ 20.626282  ]\n",
      " [  0.07913553]\n",
      " [-10.959413  ]\n",
      " [  2.3583317 ]]\n"
     ]
    }
   ],
   "source": [
    "for d in multi_eval_dataset.create_dict_iterator():\n",
    "    data = d[\"data\"]\n",
    "    break\n",
    "\n",
    "output = net(data)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 自定义网络的权重共享\n",
    "\n",
    "自定义训练和评估网络章节中已经介绍过权重共享的机制，使用MindSpore构建不同网络结构时，只要这些网络结构是在同一个实例的基础上封装的，那这个实例中的所有权重便是共享的，一个网络结构中的权重发生变化，意味着其他网络结构中的权重同步发生了变化。\n",
    "\n",
    "在使用Model进行训练时，对于简单的场景，`Model`内部使用`nn.WithLossCell`、`nn.TrainOneStepCell`和`nn.WithEvalCell`在前向`network`实例的基础上构建训练和评估网络，`Model`本身确保了推理、训练、评估网络之间权重共享。但对于自定义使用Model的场景，用户需要注意前向网络仅实例化一次。如果构建训练网络和评估网络时分别实例化前向网络，那在使用`eval`进行模型评估时，便需要手动加载训练网络中的权重，否则模型评估使用的将是初始的权重值。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MindSpore",
   "language": "python",
   "name": "mindspore"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
