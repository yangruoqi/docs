{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 训练和评估\n",
    "\n",
    "[![下载Notebook](https://gitee.com/mindspore/docs/raw/master/resource/_static/logo_notebook.png)](https://obs.dualstack.cn-north-4.myhuaweicloud.com/mindspore-website/notebook/tutorials-develop/tutorials/zh_cn/mindspore_custom_train_and_eval_net.ipynb)&emsp;[![下载样例代码](https://gitee.com/mindspore/docs/raw/master/resource/_static/logo_download_code.png)](https://obs.dualstack.cn-north-4.myhuaweicloud.com/mindspore-website/notebook/tutorials-develop/tutorials/zh_cn/mindspore_custom_train_and_eval_net.py)&emsp;[![查看源文件](https://gitee.com/mindspore/docs/raw/master/resource/_static/logo_source.png)](https://gitee.com/mindspore/docs/blob/tutorials-develop/tutorials/source_zh_cn/advance/network/custom_train_and_eval_net.ipynb)\n",
    "\n",
    "前面章节讲解了MindSpore构建网络所使用的基本元素，如MindSpore的网络基本单元、损失函数、优化器和评价函数等。\n",
    "\n",
    "本章重点介绍如何使用这些元素自定义训练和评估网络。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 构建训练和评估\n",
    "\n",
    "构建训练网络首先需要构建前向网络，然后在前向网络的基础上叠加损失函数、反向传播和优化器。\n",
    "\n",
    "### 定义数据集\n",
    "\n",
    "如下示例定义`get_data`函数生成样本数据及对应的标签，定义`create_dataset`函数加载自定义数据集。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mindspore.dataset as ds\n",
    "import numpy as np\n",
    "\n",
    "def get_data(num, w=2.0, b=3.0):\n",
    "    \"\"\"生成样本数据及对应的标签\"\"\"\n",
    "    for _ in range(num):\n",
    "        x = np.random.uniform(-10.0, 10.0)\n",
    "        noise = np.random.normal(0, 1)\n",
    "        y = x * w + b + noise\n",
    "        yield np.array([x]).astype(np.float32), np.array([y]).astype(np.float32)\n",
    "\n",
    "def create_dataset(num_data, batch_size=16):\n",
    "    \"\"\"生成数据集\"\"\"\n",
    "    dataset = ds.GeneratorDataset(list(get_data(num_data)), column_names=['data', 'label'])\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 构建前向网络\n",
    "\n",
    "使用`nn.Cell`构建前向网络，如下示例定义一个简单的线性回归网络`LinearNet`："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import mindspore.nn as nn\n",
    "from mindspore.common.initializer import Normal\n",
    "\n",
    "class LinearNet(nn.Cell):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc = nn.Dense(1, 1, Normal(0.02), Normal(0.02))\n",
    "\n",
    "    def construct(self, x):\n",
    "        return self.fc(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 构建训练流程\n",
    "\n",
    "MindSpore的`nn`模块提供了训练网络封装函数`TrainOneStepCell`，用来封装网络和优化器。其参数如下：\n",
    "\n",
    "- `network`：训练网络，只支持单输出网络。\n",
    "- `optimizer`： 用于更新网络参数的优化器。\n",
    "- `sens`：反向传播的输入，缩放系数，默认值为1.0。\n",
    "\n",
    "如下示例使用`nn.TrainOneStepCell`将上述定义的线性回归网络封装成一个训练网络，并执行训练，打印损失值。\n",
    "\n",
    "示例代码中使用`set_train`通过`mode`参数指定模型是否为训练模式，其中`mode`参数默认为True，即默认情况下为训练模式，若`mode`为False，则为评估或推理模式。\n",
    "\n",
    "若模型使用了Dropout层或Batch Normalization层，训练模式下会采用Dropout层或Batch Normalization层来防止模型过拟合，非训练模式下不使用。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-31T07:16:16.275751Z",
     "start_time": "2021-12-31T07:16:16.256615Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "153.5598\n",
      "43.35615\n",
      "8.523341\n",
      "20.466568\n",
      "57.1834\n",
      "50.924675\n",
      "32.354282\n",
      "16.914108\n",
      "8.872335\n",
      "16.288094\n",
      "52.25926\n",
      "50.773113\n",
      "25.39719\n",
      "3.8109884\n",
      "9.644215\n",
      "36.11618\n",
      "36.34368\n",
      "21.348978\n",
      "3.87617\n",
      "5.2614326\n"
     ]
    }
   ],
   "source": [
    "# 生成训练数据集\n",
    "train_dataset = create_dataset(num_data=160)\n",
    "\n",
    "net = LinearNet()\n",
    "crit = nn.MSELoss()\n",
    "\n",
    "# 连接前向网络与损失函数\n",
    "net_with_criterion = nn.WithLossCell(net, crit)\n",
    "\n",
    "opt = nn.Momentum(net.trainable_params(), learning_rate=0.005, momentum=0.9)\n",
    "\n",
    "# 定义训练网络，封装网络和优化器\n",
    "train_net = nn.TrainOneStepCell(net_with_criterion, opt)\n",
    "# 设置网络为训练模式\n",
    "train_net.set_train()\n",
    "\n",
    "# 获取训练过程数据\n",
    "epochs = 2\n",
    "for epoch in range(epochs):\n",
    "    for d in train_dataset.create_dict_iterator():\n",
    "        result = train_net(d[\"data\"], d[\"label\"])  # 输出损失值\n",
    "        # !!!wushuiqin, 优化训练过程的代码，epoch数量等信息格式化，参考vision里面的mointor\n",
    "        print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 构建评估流程\n",
    "\n",
    "MindSpore的`nn`模块提供了评估网络封装函数`WithEvalCell`，用来在验证集上评估模型训练的效果。其参数如下：\n",
    "\n",
    "- `network`：前向网络。\n",
    "- `loss_fn`：损失函数。\n",
    "- `add_cast_fp32`：是否将数据类型调整为float32。\n",
    "\n",
    "`nn.WithEvalCell`只接受两个输入，分别为数据`data`及其对应的标签`label`，用前面定义的前向网络和损失函数构建一个评估网络，示例如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-31T07:16:16.821621Z",
     "start_time": "2021-12-31T07:16:16.792286Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mae:  3.3398342609405516\n",
      "loss:  14.855223751068115\n"
     ]
    }
   ],
   "source": [
    "eval_dataset = create_dataset(num_data=160)\n",
    "\n",
    "# 构建评估网络\n",
    "eval_net = nn.WithEvalCell(net, crit)\n",
    "eval_net.set_train(False)\n",
    "loss = nn.Loss()\n",
    "mae = nn.MAE()\n",
    "\n",
    "mae.clear()\n",
    "loss.clear()\n",
    "\n",
    "# 遍历评估数据集\n",
    "for data in eval_dataset.create_dict_iterator():\n",
    "    outputs = eval_net(data[\"data\"], data[\"label\"])\n",
    "    mae.update(outputs[1], outputs[2])\n",
    "    loss.update(outputs[0])\n",
    "\n",
    "# 评估结果\n",
    "mae_result = mae.eval()\n",
    "loss_result = loss.eval()\n",
    "\n",
    "print(\"mae: \", mae_result)\n",
    "print(\"loss: \", loss_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 自定义训练和评估\n",
    "\n",
    "### 自定义训练网络\n",
    "\n",
    "[自定义损失函数章节](https://mindspore.cn/tutorials/zh-CN/master/intermediate/build_net/loss.html#%E5%A4%9A%E6%A0%87%E7%AD%BE%E6%A8%A1%E5%9E%8B%E8%AE%AD%E7%BB%83)已经介绍了使用`nn.WithLossCell`将前向网络与损失函数连接起来，本节将介绍如何自定义训练网络。\n",
    "\n",
    "如下示例定义`CustomTrainOneStepCell`函数来封装网络和优化器。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CustomTrainOneStepCell<\n",
       "  (network): WithLossCell<\n",
       "    (_backbone): LinearNet<\n",
       "      (fc): Dense<input_channels=1, output_channels=1, has_bias=True>\n",
       "      >\n",
       "    (_loss_fn): MSELoss<>\n",
       "    >\n",
       "  (optimizer): Momentum<>\n",
       "  >"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import mindspore.ops as ops\n",
    "\n",
    "class CustomTrainOneStepCell(nn.Cell):\n",
    "    \"\"\"自定义训练网络\"\"\"\n",
    "\n",
    "    def __init__(self, network, optimizer, sens=1.0):\n",
    "        \"\"\"入参有三个：训练网络，优化器和反向传播缩放比例\"\"\"\n",
    "        super(CustomTrainOneStepCell, self).__init__(auto_prefix=False)\n",
    "        self.network = network                    # 定义前向网络\n",
    "        self.network.set_grad()                   # 构建反向网络\n",
    "        self.optimizer = optimizer                # 定义优化器\n",
    "        self.weights = self.optimizer.parameters  # 待更新参数\n",
    "        self.grad = ops.GradOperation(get_by_list=True, sens_param=True)  # 反向传播获取梯度\n",
    "\n",
    "    def construct(self, *inputs):\n",
    "        loss = self.network(*inputs)                    # 执行前向网络，计算当前输入的损失函数值\n",
    "        grads = self.grad(self.network, self.weights)(*inputs, loss)  # 进行反向传播，计算梯度\n",
    "        loss = ops.depend(loss, self.optimizer(grads))  # 使用优化器更新梯度\n",
    "        return loss\n",
    "\n",
    "# 定义训练网络\n",
    "custom_train_net = CustomTrainOneStepCell(net_with_criterion, opt)\n",
    "\n",
    "# 设置网络为训练模式\n",
    "custom_train_net.set_train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 自定义评估网络\n",
    "\n",
    "由于`nn.WithEvalCell`只有两个输入`data`和`label`，对于多个数据或多个标签的场景显然不适用，此时如果想要构建评估网络就需要自定义评估网络。\n",
    "\n",
    "在自定义时，如不需要损失函数作为评价指标，则无需定义`loss_fn`。当输入为多数据或多标签时，可参考如下示例来自定义评估网络。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CustomWithEvalCell<\n",
       "  (network): LinearNet<\n",
       "    (fc): Dense<input_channels=1, output_channels=1, has_bias=True>\n",
       "    >\n",
       "  >"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class CustomWithEvalCell(nn.Cell):\n",
    "\n",
    "    def __init__(self, network):\n",
    "        super(CustomWithEvalCell, self).__init__(auto_prefix=False)\n",
    "        self.network = network\n",
    "\n",
    "    def construct(self, data, label1, label2):\n",
    "        \"\"\"输入数据为三个：一个数据及其对应的两个标签\"\"\"\n",
    "        outputs = self.network(data)\n",
    "        return outputs, label1, label2\n",
    "\n",
    "custom_eval_net = CustomWithEvalCell(net)\n",
    "custom_eval_net.set_train(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 网络的权重共享\n",
    "\n",
    "========\n",
    "\n",
    "!!! wushuiqin, 把Models的权重共享的内容，融合到这里面。\n",
    "\n",
    "网络的权重共享\n",
    "\n",
    "自定义训练和评估网络章节中已经介绍过权重共享的机制，使用MindSpore构建不同网络结构时，只要这些网络结构是在同一个实例的基础上封装的，那这个实例中的所有权重便是共享的，一个网络结构中的权重发生变化，意味着其他网络结构中的权重同步发生了变化。\n",
    "\n",
    "在使用Model进行训练时，对于简单的场景，`Model`内部使用`nn.WithLossCell`、`nn.TrainOneStepCell`和`nn.WithEvalCell`在前向`network`实例的基础上构建训练和评估网络，`Model`本身确保了推理、训练、评估网络之间权重共享。\n",
    "\n",
    "但对于自定义使用Model的场景，用户需要注意前向网络仅实例化一次。如果构建训练网络和评估网络时分别实例化前向网络，那在使用`eval`进行模型评估时，便需要手动加载训练网络中的权重，否则模型评估使用的将是初始的权重值。\n",
    "\n",
    "========\n",
    "\n",
    "通过前面的介绍可以看出，前向网络、训练网络和评估网络具有不同的逻辑，因此在需要时我们会构建三张网络。若使用训练好的模型进行评估和推理，需要推理和评估网络中的权重值与训练网络中相同。\n",
    "\n",
    "使用模型保存和加载接口，将训练好的模型保存下来，再加载到评估和推理网络中，可以确保权重值相同。在训练平台上完成模型训练，但在推理平台进行推理时，模型保存与加载是必不可少的。\n",
    "\n",
    "在网络调测过程中，或使用边训练边验证方式进行模型调优时，往往在同一Python脚本中完成模型训练，评估或推理，此时MindSpore的权重共享机制可确保不同网络间的权重一致性。\n",
    "\n",
    "使用MindSpore构建不同网络结构时，只要这些网络结构是在一个实例的基础上封装的，那这个实例中的所有权重便是共享的，一个网络中的权重发生变化，意味着其他网络中的权重同步发生了变化。\n",
    "\n",
    "如下示例中，定义训练和评估网络时便使用了权重共享机制："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-31T07:16:17.017589Z",
     "start_time": "2021-12-31T07:16:16.991264Z"
    }
   },
   "outputs": [],
   "source": [
    "net = LinearNet()\n",
    "# 设定损失函数并连接前向网络与损失函数\n",
    "crit = nn.MSELoss()\n",
    "net_with_criterion = nn.WithLossCell(net, crit)\n",
    "# 设定优化器\n",
    "opt = nn.Adam(params=net.trainable_params())\n",
    "# 定义训练网络\n",
    "train_net = nn.TrainOneStepCell(net_with_criterion, opt)\n",
    "train_net.set_train()\n",
    "# 构建评估网络\n",
    "eval_net = nn.WithEvalCell(net, crit)\n",
    "eval_net.set_train(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`train_net`和`eval_net`均在`net`实例的基础上封装，因此在进行模型评估时，不需要加载`train_net`的权重。\n",
    "\n",
    "若在构建`eval_net`时重新的定义前向网络，那`train_net`和`eval_net`之间便没有共享权重，如下：\n",
    "\n",
    "!!! 上下代码雷同过多，把已经定义过的不用重复声明，把区别代码放出来即可。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-31T07:16:17.046932Z",
     "start_time": "2021-12-31T07:16:17.018611Z"
    }
   },
   "outputs": [],
   "source": [
    "# 实例化前向网络\n",
    "net = LinearNet()\n",
    "# 设定损失函数并连接前向网络与损失函数\n",
    "crit = nn.MSELoss()\n",
    "net_with_criterion = nn.WithLossCell(net, crit)\n",
    "# 设定优化器\n",
    "opt = nn.Adam(params=net.trainable_params())\n",
    "# 定义训练网络\n",
    "train_net = nn.TrainOneStepCell(net_with_criterion, opt)\n",
    "train_net.set_train()\n",
    "\n",
    "# 再次实例化前向网络\n",
    "net2 = LinearNet()\n",
    "# 构建评估网络\n",
    "eval_net = nn.WithEvalCell(net2, crit)\n",
    "eval_net.set_train(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "此时，若要在模型训练后进行评估，就需要将`train_net`中的权重加载到`eval_net`中。在同一脚本中进行模型训练、评估和推理时，利用好权重共享机制不失为一种更简便的方式。\n",
    "\n",
    "本章主要讲解了自定义训练网络和评估网络，后续章节会进一步讲解如何通过高阶API `Model`进行模型训练和评估。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
